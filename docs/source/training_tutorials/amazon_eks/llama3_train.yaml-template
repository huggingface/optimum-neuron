apiVersion: v1
kind: Service
metadata:
  name: etcd
  namespace: kubeflow
spec:
  ports:
    - name: etcd-client-port
      port: 2379
      protocol: TCP
      targetPort: 2379
  selector:
    app: etcd

---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: etcd
  name: etcd
  namespace: kubeflow
spec:
  replicas: 1
  selector:
    matchLabels:
      app: etcd
  template:
    metadata:
      labels:
        app: etcd
    spec:
      containers:
        - name: etcd
          command: ["/usr/local/bin/etcd"]
          args:
            - "--data-dir"
            - "/var/lib/etcd"
            - "--enable-v2"
            - "--listen-client-urls"
            - "http://0.0.0.0:2379"
            - "--advertise-client-urls"
            - "http://0.0.0.0:2379"
            - "--initial-cluster-state"
            - "new"
          image: quay.io/coreos/etcd:latest
          ports:
            - containerPort: 2379
              name: client
              protocol: TCP
            - containerPort: 2380
              name: server
              protocol: TCP
      restartPolicy: Always

---
apiVersion: "kubeflow.org/v1"
kind: PyTorchJob
metadata:
  name: ${JOB_NAME}
  namespace: kubeflow
spec:
  elasticPolicy:
    rdzvBackend: etcd
    rdzvHost: etcd
    rdzvPort: 2379
    minReplicas: 1
    maxReplicas: 64
    maxRestarts: 100
    metrics:
      - type: Resource
        resource:
          name: cpu
          target:
            type: Utilization
            averageUtilization: 90
  pytorchReplicaSpecs:
    Worker:
      replicas: ${NUM_NODES}
      restartPolicy: OnFailure
      template:
        metadata:
          labels:
            app: ${JOB_NAME}
        spec:
          volumes:
            - name: shmem
              hostPath:
                path: /dev/shm
            - name: persistent-storage
              persistentVolumeClaim:
                claimName: ${FSX_CLAIM}
            - name: local
              hostPath:
                path: /dev
            - name: hyperpod
              hostPath:
                path: /var/log/aws/clusters
          nodeSelector:
            node.kubernetes.io/instance-type: ${INSTANCE_TYPE}
          containers:
            - name: pytorch
              image: ${IMAGE_URI}
              imagePullPolicy: Always
              resources:
                requests:
                  aws.amazon.com/neuron: ${NEURON_PER_NODE}
                  vpc.amazonaws.com/efa: ${EFA_PER_NODE}
                limits:
                  aws.amazon.com/neuron: ${NEURON_PER_NODE}
                  vpc.amazonaws.com/efa: ${EFA_PER_NODE}
              env:
              - name: MODEL_NAME
                value: ${HF_MODEL_NAME}
              - name: NEURON_RT_NUM_CORES
                value: "32"
              - name: NUM_NEURONCORES
                value: "32"
              - name: TPU_NUM_DEVICES
                value: "32"
              - name: TPU_CHIPS_PER_HOST_BOUNDS
                value: "32"
              - name: MALLOC_ARENA_MAX
                value: "64"
              - name: NEURON_RT_ASYNC_EXEC_MAX_INFLIGHT_REQUESTS
                value: "5"
              - name: NEURON_FUSE_SOFTMAX
                value: "1"
              - name: FI_PROVIDER
                value: ${FI_PROVIDER}
              - name: FI_EFA_USE_DEVICE_RDMA
                value: "1"
              - name: FI_EFA_FORK_SAFE
                value: "1"
              - name: NEURON_CC_FLAGS
                value: "--model-type transformer --distribution-strategy=llm-training --enable-saturate-infinity --cache_dir=${NEURON_CACHE_DIR} --target=trn1 --auto-cast=none"
              command:
                - torchrun
                - --nproc_per_node=8
                - --nnodes=${NUM_NODES}
                - run_clm.py
                - --model_name_or_path=${HF_MODEL_NAME}
                - --token=${HF_ACCESS_TOKEN}
                - --dataset_name=${DATASET_NAME}
                - --dataset_config_name=${DATASET_CONFIG_NAME}
                - --streaming=False
                - --cache_dir=${TOKENIZED_DATA_PATH}
                - --num_train_epochs=1
                - --do_train
                - --learning_rate=1e-4
                - --max_steps=${MAX_STEPS}
                - --per_device_train_batch_size=${BATCH_SIZE}
                - --gradient_accumulation_steps=8
                - --gradient_checkpointing
                - --block_size=4096
                - --bf16
                - --torch_dtype=bfloat16
                - --weight_decay=0.01
                - --max_grad_norm=1.0
                - --lr_scheduler_type=linear
                - --tensor_parallel_size=8
                - --pipeline_parallel_size=1
                - --logging_steps=1
                - --save_total_limit=1
                - --output_dir=${CHECKPOINT_DIR}
                - --overwrite_output_dir
              volumeMounts:
                - name: shmem
                  mountPath: /dev/shm
                - name: persistent-storage
                  mountPath: /fsx
                - name: hyperpod
                  mountPath: /var/log/aws/clusters
