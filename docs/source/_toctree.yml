- sections:
  - local: index
    title: ðŸ¤— Optimum Neuron
  - local: installation
    title: Installation
  - local: quickstart
    title: Quickstart
  - local: containers
    title: Optimum Containers
  - sections:
    - local: training_tutorials/notebooks
      title: Notebooks
    - local: training_tutorials/fine_tune_bert
      title: Fine-tune BERT for Text Classification on AWS Trainium
    - local: training_tutorials/finetune_llm
      title: Fine-tune Llama 3 8B on AWS Trainium
    - local: training_tutorials/sft_lora_finetune_llm
      title: Fine-tune Llama 3 8B on with LoRA and the SFTTrainer
    title: Training Tutorials
  - sections:
    - local: inference_tutorials/notebooks
      title: Notebooks
    - local: inference_tutorials/llama2-13b-chatbot
      title: Create your own chatbot with llama-2-13B on AWS Inferentia
    - local: inference_tutorials/sentence_transformers
      title: Sentence Transformers on AWS Inferentia
    - local: inference_tutorials/stable_diffusion
      title: Generate images with Stable Diffusion models on AWS Inferentia
    title: Inference Tutorials
  - sections:
    - local: guides/setup_aws_instance
      title: Set up AWS Trainium instance
    - local: guides/sagemaker
      title: Training and Deployment using Amazon Sagemaker
    - local: guides/cache_system
      title: Neuron model cache
    - local: guides/fine_tune
      title: Fine-tune Transformers with AWS Trainium
    - local: guides/distributed_training
      title: Distributed Training
    - local: guides/export_model
      title: Export a model to Inferentia
    - local: guides/pipelines
      title: Inference pipelines with AWS Neuron
    - local: guides/neuronx_tgi
      title: NeuronX Text-generation-inference for AWS inferentia2
    title: How-To Guides
  - sections:
    - local: benchmarks/inferentia-llama2-7b
      title: Llama2 7b on AWS Inferentia2
    - local: benchmarks/inferentia-llama2-13b
      title: Llama2 13b on AWS Inferentia2
    - local: benchmarks/inferentia-mistral-v2
      title: Mistral v0.2 7b on AWS Inferentia2
    - local: benchmarks/inferentia-llama3-8b
      title: Llama-3 8B on AWS Inferentia2
    title: Benchmarks
  - sections:
    - local: community/contributing
      title: Add support for a new model architecture
    title: Contribute
  - sections:
    - local: package_reference/trainer
      title: Neuron Trainer
    - local: package_reference/distributed
      title: Neuron Distributed
    - local: package_reference/supported_models
      title: Supported Architectures
    - local: package_reference/export
      title: Neuron Exporter
    - local: package_reference/modeling
      title: Neuron Models
    title: Reference
  title: Optimum Neuron
  isExpanded: true
