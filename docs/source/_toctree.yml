- sections:
  - local: index
    title: ðŸ¤— Optimum Neuron
  - local: ec2-setup
    title: EC2 Setup
  - local: quickstart
    title: Quickstart
  - local: supported_architectures
    title: Supported Architectures
  - local: containers
    title: Optimum Containers
  - sections:
    - local: guides/cache_system
      title: Neuron model cache
    - local: guides/distributed_training
      title: Distributed Training
    - local: guides/export_model
      title: Export a model to Inferentia
    - local: guides/pipelines
      title: Inference pipelines with AWS Neuron
    - local: guides/neuronx_tgi
      title: NeuronX Text-generation-inference for AWS inferentia2
    - local: guides/vllm_plugin
      title: Inference on Neuron platforms using vLLM
    - local: guides/benchmark
      title: Benchmarking LLM performance with TGI on AWS Inferentia2
    title: How-To Guides
  - sections:
    - local: training_tutorials/fine_tune_bert
      title: Fine-tune BERT for Text Classification
    - isExpanded: true
      sections:
      - local: training_tutorials/finetune_llms_overview
        title: Overview
      - local: training_tutorials/finetune_llama
        title: Instruction Fine-Tuning of Llama 3.1 8B with LoRA
      - local: training_tutorials/finetune_qwen3
        title: Fine-Tune Qwen3 8B with LoRA
      - local: training_tutorials/pretraining_hyperpod_llm
        title: Continuous Pretraining of Llama 3.2 1B on SageMaker Hyperpod
      title: How-to Fine-Tune LLMs
    title: Training Tutorials
  - sections:
      - isExpanded: false
        sections:
        - local: inference_tutorials/notebooks
          title: Notebooks
        - local: inference_tutorials/llama2-13b-chatbot
          title: Create your own chatbot with llama-2-13B on AWS Inferentia
        - local: inference_tutorials/sentence_transformers
          title: Sentence Transformers on AWS Inferentia
        title: EC2
      - isExpanded: false
        sections:
        - local: inference_tutorials/deploy-llama-3-3-70b
          title: Deploy Llama 3.3 70B on AWS Inferentia2 with SageMaker
        - local: inference_tutorials/deploy-mixtral-8x7b
          title: Deploy Mixtral 8x7B on AWS Inferentia2 with SageMaker
        title: SageMaker
    title: Inference Tutorials
  - sections:
    - local: benchmarks/inferentia-llama3.1-8b
      title: Llama-3.1 8B on AWS Inferentia2
    - local: benchmarks/inferentia-llama3.3-70b
      title: Llama-3.3 70B on AWS Inferentia2
    title: Inference Benchmarks
  - sections:
    - local: contribute/dev_environment
      title: Set up a development environment
    - local: contribute/contribute_for_training
      title: Add a custom model implementation for training
    - local: contribute/contribute_for_inference
      title: Add inference support for a new model architecture
    title: Contribute
  - sections:
    - local: training_api/trainer
      title: Neuron Trainer
    - local: training_api/trl_trainers
      title: Neuron TRL Trainers
    - local: training_api/transformations
      title: Model Weight Transformation Specs
    - local: training_api/lora
      title: LoRA for Neuron
    title: Training API
  - sections:
    - isExpanded: false
      sections:
      - isExpanded: false
        sections:
        - local: model_doc/transformers/bert
          title: BERT
        title: TEXT MODELS
      - isExpanded: false
        sections:
        - local: model_doc/transformers/yolos
          title: YOLOS
        title: VISION MODELS
      - isExpanded: false
        sections:
        - local: model_doc/transformers/whisper
          title: Whisper
        title: AUDIO MODELS
      - isExpanded: false
        sections:
        - local: model_doc/transformers/clip
          title: CLIP
        title: MULTIMODAL MODELS
      title: Transformers Models
    - isExpanded: false
      sections:
      - local: model_doc/sentence_transformers/overview
        title: Overview
      title: SENTENCE TRANSFORMERS
    - isExpanded: false
      sections:
      - local: model_doc/diffusers/controlnet
        title: ControlNet
      - local: model_doc/diffusers/flux
        title: Flux
      - local: model_doc/diffusers/pix2pix
        title: InstructPix2Pix
      - local: model_doc/diffusers/lcm
        title: Latent Consistency Models
      - local: model_doc/diffusers/pixart_alpha
        title: PixArt-Î±
      - local: model_doc/diffusers/pixart_sigma
        title: PixArt-Î£
      - isExpanded: false
        sections:
        - local: model_doc/diffusers/stable_diffusion
          title: Stable Diffusion
        - local: model_doc/diffusers/stable_diffusion_xl
          title: Stable Diffusion XL
        - local: model_doc/diffusers/sdxl_turbo
          title: SDXL Turbo
        title: STABLE DIFFUSION
      - isExpanded: false
        sections:
        - local: model_doc/diffusers/lora
          title: LoRA
        - local: model_doc/diffusers/ip_adapter
          title: IP-Adapter
        title: SPECIFIC PIPELINES and ADAPTERS
      title: DIFFUSERS PIPELINES
    - local: model_doc/modeling_auto
      title: Auto Model Classes
    title: Models and Pipelines Inference API
  title: Optimum Neuron
  isExpanded: true
