- sections:
  - local: index
    title: ðŸ¤— Optimum Neuron
  - local: installation
    title: Installation
  - local: quickstart
    title: Quickstart
  - local: containers
    title: Optimum Containers
  - sections:
    - sections:
      - isExpanded: false
        sections:
        - local: training_tutorials/notebooks
          title: Notebooks
        - local: training_tutorials/fine_tune_bert
          title: Fine-tune BERT for Text Classification
        - local: training_tutorials/sft_lora_finetune_llm
          title: Fine-tune Llama 3 8B with LoRA and the SFTTrainer
        title: EC2
      title: Training Tutorials
    - sections:
      - isExpanded: false
        sections:
        - local: inference_tutorials/notebooks
          title: Notebooks
        - local: inference_tutorials/llama2-13b-chatbot
          title: Create your own chatbot with llama-2-13B on AWS Inferentia
        - local: inference_tutorials/sentence_transformers
          title: Sentence Transformers on AWS Inferentia
        - local: inference_tutorials/stable_diffusion
          title: Generate images with Stable Diffusion models on AWS Inferentia
        title: EC2
      - isExpanded: false
        sections:
        - local: inference_tutorials/deploy-llama-3-3-70b
          title: Deploy Llama 3.3 70B on AWS Inferentia2 with SageMaker
        - local: inference_tutorials/deploy-mixtral-8x7b
          title: Deploy Mixtral 8x7B on AWS Inferentia2 with SageMaker
        - local: inference_tutorials/deploy-sdxl
          title: Deploy Stable Diffusion on AWS Inferentia2 with Sagemaker
        title: SageMaker
      title: Inference Tutorials
    title: Tutorials
  - sections:
    - local: guides/setup_aws_instance
      title: Get Started on Amazon EC2
    - local: guides/sagemaker
      title: Training and Deployment using Amazon Sagemaker
    - local: guides/cache_system
      title: Neuron model cache
    - local: guides/fine_tune
      title: Fine-tune Transformers with AWS Trainium
    - local: guides/distributed_training
      title: Distributed Training
    - local: guides/export_model
      title: Export a model to Inferentia
    - local: guides/pipelines
      title: Inference pipelines with AWS Neuron
    - local: guides/neuronx_tgi
      title: NeuronX Text-generation-inference for AWS inferentia2
    title: How-To Guides
  - sections:
    - local: benchmarks/inferentia-mistral-small
      title: Mistral Small on AWS Inferentia2
    - local: benchmarks/inferentia-llama3.1-8b
      title: Llama-3.1 8B on AWS Inferentia2
    title: Benchmarks
  - sections:
    - local: community/contributing
      title: Add support for a new model architecture
    title: Contribute
  - sections:
    - local: package_reference/trainer
      title: Neuron Trainer
    - local: package_reference/distributed
      title: Neuron Distributed
    - local: package_reference/supported_models
      title: Supported Architectures
    - local: package_reference/export
      title: Neuron Exporter
    - local: package_reference/modeling
      title: Neuron Models
    title: Reference
  title: Optimum Neuron
  isExpanded: true
