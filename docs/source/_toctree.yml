- sections:
  - local: index
    title: ðŸ¤— Optimum Neuron
  - local: installation
    title: Installation
  - local: quickstart
    title: Quickstart
  - local: containers
    title: Optimum Containers
  - sections:
    - local: guides/setup_aws_instance
      title: Get Started on Amazon EC2
    - local: guides/sagemaker
      title: Training and Deployment using Amazon Sagemaker
    - local: guides/cache_system
      title: Neuron model cache
    - local: guides/fine_tune
      title: Fine-tune Transformers with AWS Trainium
    - local: guides/distributed_training
      title: Distributed Training
    - local: guides/export_model
      title: Export a model to Inferentia
    - local: guides/pipelines
      title: Inference pipelines with AWS Neuron
    - local: guides/neuronx_tgi
      title: NeuronX Text-generation-inference for AWS inferentia2
    - local: guides/vllm_plugin
      title: Inference on Neuron platforms using vLLM
    title: How-To Guides
  - sections:
    - sections:
      - isExpanded: false
        sections:
        - local: training_tutorials/notebooks
          title: Notebooks
        - local: training_tutorials/fine_tune_bert
          title: Fine-tune BERT for Text Classification
        - local: training_tutorials/sft_lora_finetune_llm
          title: Fine-tune Llama 3 8B with LoRA and the SFTTrainer
        - local: training_tutorials/finetune_qwen3
          title: Fine-tune Qwen 3 on AWS Trainium
        - local: training_tutorials/pretraining_hyperpod_llm
          title: Continuous Pretraining of Llama 3.2 1B on SageMaker Hyperpod
        title: EC2
      title: Training Tutorials
    - sections:
      - isExpanded: false
        sections:
        - local: inference_tutorials/notebooks
          title: Notebooks
        - local: inference_tutorials/llama2-13b-chatbot
          title: Create your own chatbot with llama-2-13B on AWS Inferentia
        - local: inference_tutorials/sentence_transformers
          title: Sentence Transformers on AWS Inferentia
        title: EC2
      - isExpanded: false
        sections:
        - local: inference_tutorials/deploy-llama-3-3-70b
          title: Deploy Llama 3.3 70B on AWS Inferentia2 with SageMaker
        - local: inference_tutorials/deploy-mixtral-8x7b
          title: Deploy Mixtral 8x7B on AWS Inferentia2 with SageMaker
        title: SageMaker
      title: Inference Tutorials
    title: Tutorials
  - sections:
    - isExpanded: false
      sections:
      - isExpanded: false
        sections:
        - local: model_doc/transformers/bert
          title: BERT
        title: TEXT MODELS
      - isExpanded: false
        sections:
        - local: model_doc/transformers/yolos
          title: YOLOS
        title: VISION MODELS
      - isExpanded: false
        sections:
        - local: model_doc/transformers/whisper
          title: Whisper
        title: AUDIO MODELS
      - isExpanded: false
        sections:
        - local: model_doc/transformers/clip
          title: CLIP
        title: MULTIMODAL MODELS
      title: Transformers Models
    - isExpanded: false
      sections:
      - local: model_doc/sentence_transformers/overview
        title: Overview
      title: SENTENCE TRANSFORMERS
    - isExpanded: false
      sections:
      - local: model_doc/diffusers/controlnet
        title: ControlNet
      - local: model_doc/diffusers/flux
        title: Flux
      - local: model_doc/diffusers/pix2pix
        title: InstructPix2Pix
      - local: model_doc/diffusers/lcm
        title: Latent Consistency Models
      - local: model_doc/diffusers/pixart_alpha
        title: PixArt-Î±
      - local: model_doc/diffusers/pixart_sigma
        title: PixArt-Î£
      - isExpanded: false
        sections:
        - local: model_doc/diffusers/stable_diffusion
          title: Stable Diffusion
        - local: model_doc/diffusers/stable_diffusion_xl
          title: Stable Diffusion XL
        - local: model_doc/diffusers/sdxl_turbo
          title: SDXL Turbo
        title: STABLE DIFFUSION
      - isExpanded: false
        sections:
        - local: model_doc/diffusers/lora
          title: LoRA
        - local: model_doc/diffusers/ip_adapter
          title: IP-Adapter
        title: SPECIFIC PIPELINES and ADAPTERS
      title: DIFFUSERS PIPELINES
    title: Models and Pipelines
  - sections:
    - local: benchmarks/inferentia-llama3.1-8b
      title: Llama-3.1 8B on AWS Inferentia2
    - local: benchmarks/inferentia-llama3.3-70b
      title: Llama-3.3 70B on AWS Inferentia2
    title: Benchmarks
  - sections:
    - local: community/contributing
      title: Add support for a new model architecture
    title: Contribute
  - sections:
    - local: package_reference/trainer
      title: Neuron Trainer
    - local: package_reference/supported_models
      title: Supported Architectures
    - local: package_reference/export
      title: Neuron Exporter
    - local: package_reference/modeling
      title: Neuron Models
    title: API
  title: Optimum Neuron
  isExpanded: true
