# NeuronX Text-generation-inference for AWS inferentia2

Text Generation Inference ([TGI](https://huggingface.co/docs/text-generation-inference/)) is a toolkit for deploying and serving Large Language Models (LLMs).

A [neuron backend](https://huggingface.co/docs/text-generation-inference/en/backends/neuron) allows to deploy TGI for Trainium and Inferentia chips.
