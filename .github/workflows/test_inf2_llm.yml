name: Optimum neuron / Test INF2 LLM

on:
  # Trigger after sanity check completes
  workflow_run:
    workflows: ["Optimum neuron / Sanity check"]
    types:
      - completed

concurrency:
  group: ${{ github.workflow }}-${{ github.event.workflow_run.head_branch || github.run_id }}
  cancel-in-progress: true

jobs:
  check-and-gate:
    name: Check Sanity and Paths
    runs-on: ubuntu-22.04
    outputs:
      should_run: ${{ steps.check.outputs.should_run }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Check sanity and paths
        id: check
        uses: ./.github/actions/check-sanity-and-paths
        with:
          path_patterns: |
            ^pyproject\.toml$
            ^optimum/commands/export/neuronx\.py$
            ^optimum/exporters/neuron/__main__\.py$
            ^optimum/neuron/configuration_utils\.py$
            ^optimum/neuron/modeling_base\.py$
            ^optimum/neuron/models/[^/]+\.py$
            ^optimum/neuron/models/inference/auto_models\.py$
            ^optimum/neuron/models/inference/modeling_utils\.py$
            ^optimum/neuron/models/inference/backend/.*\.py$
            ^optimum/neuron/models/inference/(granite|llama|llama4|mixtral|phi3|qwen2|qwen3|qwen3_moe)/.*\.py$
            ^optimum/neuron/pipelines/transformers/base\.py$
            ^optimum/neuron/utils/.*\.py$
            ^optimum/neuron/version\.py$
            ^tests/fixtures/llm/.*\.py$
            ^tests/decoder/.*\.py$
            ^\.github/workflows/test_inf2_llm\.yml$

  do-the-job:
    name: Run INF2 LLM tests
    needs: check-and-gate
    if: needs.check-and-gate.outputs.should_run == 'true'
    runs-on:
      group: aws-inf2-8xlarge
    env:
      HF_XET_HIGH_PERFORMANCE: 1
    steps:
      - name: Checkout
        uses: actions/checkout@v4
      - name: Install Neuronx runtime
        uses: ./.github/actions/install_neuronx_runtime
      - name: Setup virtual environment
        uses: ./.github/actions/setup_venv
      - name: Export test models
        run: |
          source aws_neuron_venv_pytorch/bin/activate
          export HF_TOKEN=${{ secrets.HF_TOKEN_OPTIMUM_NEURON_CI }}
          python tests/fixtures/llm/export_models.py
      - name: Run LLM utils tests
        run: |
          source aws_neuron_venv_pytorch/bin/activate
          export HF_TOKEN=${{ secrets.HF_TOKEN_OPTIMUM_NEURON_CI }}
          pytest -sv tests/decoder/test_decoder_config.py
          pytest -sv tests/decoder/test_fused_logits_warper.py
          pytest -sv tests/decoder/test_device_memory.py
      - name: Run LLM export tests
        run: |
          source aws_neuron_venv_pytorch/bin/activate
          export HF_TOKEN=${{ secrets.HF_TOKEN_OPTIMUM_NEURON_CI }}
          pytest -sv tests/decoder/test_decoder_export.py
      - name: Run LLM hub tests
        run: |
          source aws_neuron_venv_pytorch/bin/activate
          export HF_TOKEN=${{ secrets.HF_TOKEN_OPTIMUM_NEURON_CI }}
          pytest -sv tests/decoder/test_decoder_hub.py
      - name: Run LLM generation tests
        run: |
          source aws_neuron_venv_pytorch/bin/activate
          export HF_TOKEN=${{ secrets.HF_TOKEN_OPTIMUM_NEURON_CI }}
          pytest -sv tests/decoder/test_decoder_generation.py
      - name: Run LLM embedding tests
        run: |
          source aws_neuron_venv_pytorch/bin/activate
          export HF_TOKEN=${{ secrets.HF_TOKEN_OPTIMUM_NEURON_CI }}
          pytest -sv tests/decoder/test_decoder_embedding.py
      - name: Run LLM pipeline tests
        run: |
          source aws_neuron_venv_pytorch/bin/activate
          export HF_TOKEN=${{ secrets.HF_TOKEN_OPTIMUM_NEURON_CI }}
          pytest -sv tests/decoder/test_decoder_pipelines.py
      - name: Run LLM module tests
        run: |
          source aws_neuron_venv_pytorch/bin/activate
          export HF_TOKEN=${{ secrets.HF_TOKEN_OPTIMUM_NEURON_CI }}
          pytest -sv tests/decoder/test_modules.py tests/decoder/test_attention.py
      - name: Run LLM cache tests
        run: |
          source aws_neuron_venv_pytorch/bin/activate
          export HF_TOKEN=${{ secrets.HF_TOKEN_OPTIMUM_NEURON_CI }}
          pytest -sv tests/decoder/test_cache.py
      - name: Run LLM CLI tests
        run: |
          source aws_neuron_venv_pytorch/bin/activate
          export HF_TOKEN=${{ secrets.HF_TOKEN_OPTIMUM_NEURON_CI }}
          pytest -sv tests/decoder/test_cli.py
      - name: Synchronize hub cache
        run: |
          source aws_neuron_venv_pytorch/bin/activate
          export HF_TOKEN=${{ secrets.HF_TOKEN_OPTIMUM_NEURON_CACHE }}
          optimum-cli neuron cache synchronize
