name: Optimum neuron / Test INF2 LLM

on:
  push:
    branches: [ main ]
    paths:
      - "pyproject.toml"
      - "optimum/commands/export/neuronx.py"
      - "optimum/exporters/neuron/__main__.py"
      - "optimum/neuron/configuration_utils.py"
      - "optimum/neuron/modeling_base.py"
      - "optimum/neuron/models/*.py"
      - "optimum/neuron/models/inference/auto_models.py"
      - "optimum/neuron/models/inference/modeling_utils.py"
      - "optimum/neuron/models/inference/backend/**.py"
      - "optimum/neuron/models/inference/granite/**.py"
      - "optimum/neuron/models/inference/llama/**.py"
      - "optimum/neuron/models/inference/llama4/**.py"
      - "optimum/neuron/models/inference/mixtral/**.py"
      - "optimum/neuron/models/inference/phi3/**.py"
      - "optimum/neuron/models/inference/qwen2/**.py"
      - "optimum/neuron/models/inference/qwen3/**.py"
      - "optimum/neuron/models/inference/qwen3_moe/**.py"
      - "optimum/neuron/pipelines/transformers/base.py"
      - "optimum/neuron/utils/**.py"
      - "optimum/neuron/version.py"
      - "tests/decoder/**.py"
      - ".github/workflows/test_inf2_llm.yml"
  pull_request:
    branches: [ main ]
    paths:
      - "pyproject.toml"
      - "optimum/commands/export/neuronx.py"
      - "optimum/exporters/neuron/__main__.py"
      - "optimum/neuron/configuration_utils.py"
      - "optimum/neuron/modeling_base.py"
      - "optimum/neuron/models/*.py"
      - "optimum/neuron/models/inference/auto_models.py"
      - "optimum/neuron/models/inference/modeling_utils.py"
      - "optimum/neuron/models/inference/backend/**.py"
      - "optimum/neuron/models/inference/granite/**.py"
      - "optimum/neuron/models/inference/llama/**.py"
      - "optimum/neuron/models/inference/llama4/**.py"
      - "optimum/neuron/models/inference/mixtral/**.py"
      - "optimum/neuron/models/inference/phi3/**.py"
      - "optimum/neuron/models/inference/qwen2/**.py"
      - "optimum/neuron/models/inference/qwen3/**.py"
      - "optimum/neuron/models/inference/qwen3_moe/**.py"
      - "optimum/neuron/pipelines/transformers/base.py"
      - "optimum/neuron/utils/**.py"
      - "optimum/neuron/version.py"
      - "tests/decoder/**.py"
      - ".github/workflows/test_inf2_llm.yml"

concurrency:
  group: ${{ github.workflow }}-${{ github.head_ref || github.run_id }}
  cancel-in-progress: true

jobs:
  do-the-job:
    name: Run INF2 LLM tests
    runs-on:
      group: aws-inf2-8xlarge
    env:
      HF_XET_HIGH_PERFORMANCE: 1
    steps:
      - name: Checkout
        uses: actions/checkout@v4
      - name: Install Neuronx runtime
        uses: ./.github/actions/install_neuronx_runtime
      - name: Prepare virtual environment
        uses: ./.github/actions/prepare_venv
      - name: Install optimum-neuron
        uses: ./.github/actions/install_optimum_neuron
      - name: Export test models
        run: |
          source aws_neuron_venv_pytorch/bin/activate
          export HF_TOKEN=${{ secrets.HF_TOKEN_OPTIMUM_NEURON_CI }}
          python tests/fixtures/llm/export_models.py
      - name: Run base LLM tests
        run: |
          source aws_neuron_venv_pytorch/bin/activate
          export HF_TOKEN=${{ secrets.HF_TOKEN_OPTIMUM_NEURON_CI }}
          pytest -sv tests/decoder/test_decoder_config.py
          pytest -sv tests/decoder/test_fused_logits_warper.py
          pytest -sv tests/decoder/test_decoder_export.py
          pytest -sv tests/decoder/test_decoder_generation.py
          pytest -sv tests/decoder/test_decoder_hub.py
          pytest -sv tests/decoder/test_decoder_pipelines.py
          pytest -sv tests/decoder/test_modules.py tests/decoder/test_attention.py
          pytest -sv tests/decoder/test_cache.py
          pytest -sv tests/decoder/test_cli.py
