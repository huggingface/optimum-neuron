name: Optimum neuron / Test INF2 Transformers inference & pipelines

on:
  # Trigger after sanity check completes
  workflow_run:
    workflows: ["Optimum neuron / Sanity check"]
    types:
      - completed

  # Daily scheduled run
  schedule:
    - cron: "0 1 * * *"  # every day at 01:00 UTC

concurrency:
  group: ${{ github.workflow }}-${{ github.event.workflow_run.head_branch || github.run_id }}
  cancel-in-progress: true

jobs:
  check-and-gate:
    name: Check Sanity and Paths
    runs-on: ubuntu-22.04
    outputs:
      should_run: ${{ steps.check.outputs.should_run }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Check sanity and paths
        id: check
        uses: ./.github/actions/check-sanity-and-paths
        with:
          path_patterns: |
            ^pyproject\.toml$
            ^optimum/commands/export/neuronx\.py$
            ^optimum/exporters/.*\.py$
            ^optimum/neuron/cache/.*\.py$
            ^optimum/neuron/modeling_base\.py$
            ^optimum/neuron/modeling_traced\.py$
            ^optimum/neuron/models/inference/(bert|clip|t5|whisper|yolos)/.*\.py$
            ^optimum/neuron/pipelines/transformers/.*\.py$
            ^optimum/neuron/utils/.*\.py$
            ^tests/inference/transformers/.*\.py$
            ^\.github/workflows/test_inf2_slow\.yml$

  do-the-job:
    name: Run INF2 tests
    needs: check-and-gate
    if: needs.check-and-gate.outputs.should_run == 'true'
    runs-on:
      group: aws-inf2-8xlarge
    steps:
      - name: Checkout
        uses: actions/checkout@v4
      - name: Install Neuronx runtime
        uses: ./.github/actions/install_neuronx_runtime
      - name: Setup virtual environment
        uses: ./.github/actions/setup_venv
      - name: Install datasets dependencies
        run: |
          sudo apt-get install ffmpeg -y
          source aws_neuron_venv_pytorch/bin/activate
          uv pip install datasets[audio]
      - name: Run transformers inference slow tests
        run: |
          source aws_neuron_venv_pytorch/bin/activate
          export HF_TOKEN=${{ secrets.HF_TOKEN_OPTIMUM_NEURON_CI }}
          pytest -m slow tests/inference/transformers/test_modeling.py
